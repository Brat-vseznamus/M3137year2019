\chapter{20 марта}

\section{Случайные величины}

%<*16>
\begin{example}\itemfix
    \begin{enumerate}
        \item Бросаем кость. \(\xi\) --- число выпавших очков. \(\xi \in \{1, 2, 3, 4, 5, 6\} \)
        \item Достали случайную микросхему из ящика. \(\xi\) --- время работы до отказа.
              \begin{enumerate}
                  \item Пусть время измеряется в часах. Тогда \(\xi \in \{0, 1, 2, 3 \dots \} \)
                  \item Пусть время измеряется точно. Тогда \(\xi \in [0, +\infty)\)
              \end{enumerate}
        \item \(\xi\) --- температура воздуха в текущий момент времени. \(\xi \in ( - 50^\circ, 50^\circ)\)
        \item \(\xi\) --- индикатор события \(A\). Обозначается \(I_A = \begin{cases}
                  0, & A \text{ не наступает} \\
                  1, & A \text{ наступает}    \\
              \end{cases}\)
    \end{enumerate}
\end{example}

\begin{definition}
    Пусть имеется вероятностное пространство \((\Omega, \mathfrak{F}, P)\). Функция \(\xi : \Omega \to \R\) называется \textbf{\(\mathfrak{F}\)-измеримой}, если \(\forall x\in \R  \ \ \{w : \xi(w) < x\} \in \mathfrak{F}\). Иными словами, прообраз \(\xi^{ - 1}( - \infty, x)\in \mathfrak{F}\).
\end{definition}

\begin{definition}
    \textbf{Случайной величиной} \(\xi\), заданной на пространстве \(\Omega, \mathfrak{F}, P\), называется \(\mathfrak{F}\)-измеримая функция \(\xi : \Omega \to \R\), ставящая в соотвествие каждому элементарному исходу некоторое вещественное число.
\end{definition}

\begin{remark}
    Не все функции являются измеримыми.
\end{remark}

\begin{example}
    Бросаем кость. \(\Omega = \{1, 2, 3, 4, 5, 6\}, \mathfrak{F} = \{\emptyset, \Omega, \{1, 3, 5\}, \{2, 4, 6\} \} \). \(\xi(i) = i\)

    Пусть \(x = 4\), \(\{w : \xi(w) < 4\} = \{1, 2, 3\} \notin \mathfrak{F}\). \(\xi\) не измеримо.
\end{example}

\begin{exercise}
    Описать класс измеримых функций для тривиальной \(\sigma\)-алгебры \(\{\emptyset, \Omega\}\)
\end{exercise}

Пусть \(\xi : \Omega \to \R\) измерима. Тогда \(P(\xi < x) = P(\underbrace{\{w : \xi(w) < x\}}_{A_x})\), т.к. \(A_x \in \mathfrak{F}\), а также:
\begin{itemize}
    \item \(\overline{A_x} = \{w : \xi(w) \geq x\} \in \mathfrak{F}\)
    \item При \(x > y\) \(A_x \setminus B_y = \{w : y \leq \xi(w) < x\} \in \mathfrak{F}\).
    \item \(B_x = \bigcap_{t = 1}^{\infty} A_{x - \frac{1}{t}} = \{w : \xi(w) \leq x\} \)
    \item \(B_x \setminus A_x = \{w : \xi(w) = x\} \in \mathfrak{F}\)
\end{itemize}

Отсюда видим, что по теореме Каратеодори вероятностную меру можно продолжить до любого борелевского множества \(B \in \mathfrak{B}\), где \(\mathfrak{B}\) --- борелевская \(\sigma\)-алгебра.

\[P(B \in \mathfrak{B}) = P(\{w : \xi(w) \in B\})\]

Итак, пусть случайная величина \(\xi\) задана на вероятностном пространстве \((\Omega, \mathfrak{F}, P)\). Тогда:
\begin{enumerate}
    \item \((\Omega, \mathfrak{F}, P) \xrightarrow{\xi} (\R, \mathfrak{B}, P)\)
    \item В свою очередь совокупность прообразов \(\xi^{ - 1}(B) \ \ \forall B\in \mathfrak{B}\) является \(\sigma\)-алгеброй \(\mathfrak{F}_\xi \subset \mathfrak{F}\). Такая \(\sigma\)-алгебра называется \textbf{\(\sigma\)-алгеброй, порожденной случайной величиной \(\xi\)}.
\end{enumerate}
%</16>

\begin{exercise}
    Найти \(\sigma\)-алгебру, порожденную индикатором \(I_A = \begin{cases} 0, & w\notin A \\ 1, & w\in A \end{cases} \)
\end{exercise}

\begin{definition}
    Функция \(P(B), B \in \mathfrak{B}\) называется \textbf{распределением вероятностей} случайной величины \(\xi(w)\), т.е. распределение с.в. это соотвествие между множествами на вещественной прямой и вероятностями случайной величины попасть в это множество.
\end{definition}

\subsection{Основные типы распределений}

\begin{enumerate}
    \item Дискретное
    \item Абсолютно непрерывное
    \item Смешанное
    \item Сингулярное --- непрерывное, но не абсолютно непрерывное
\end{enumerate}

Мы будем рассматривать только первые два. Соответствующие величины мы также будем называть дискретными или непрерывными.

%<*17>
\subsection{Дискретные случайные величины}

\begin{definition}
    Случайная величина \(\xi\) имеет \textbf{дискретное распределение}, если она принимает не более чем счётное число значений, то есть существует конечный или счётный набор чисел \(x_1 \dots x_n \dots \), такой что \(p_i = P(\xi = x_i) > 0\) и \(\sum p_i = 1\)
\end{definition}
Дискретная случайная величина задаётся законом распределения \textit{(рядом, таблицей)}.


\begin{example}
    Кость.

    \begin{tabular}{C|C|C|C|C|C|C}
        \xi & 1           & 2           & 3           & 4           & 5           & 6           \\ \hline
        P   & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6}
    \end{tabular}
\end{example}

\subsection{Основные числовые характеристики дискретной случайной величины}

\subsubsection{Математическое ожидание \textit{(среднее значение)}}

\begin{definition}
    \textbf{Математическим ожиданием} \(\E\xi\) называется число \(\E\xi = \sum_i x_ip_i\) при условии, что данный ряд сходится абсолютно. В противном случае говорят, что матожидания не существует.
\end{definition}

\begin{remark}
    Смысл: значения случайной величины группируются вокруг матожидания.
\end{remark}

\subsubsection{Дисперсия}

\begin{definition}
    \textbf{Дисперсией} \(\D\xi\) случайной величины \(\xi\) называется среднее квадратов отклонений этой величины от математического ожидания: \(\D\xi = \E(\xi - \E x)^2\) или \(\D\xi = \sum_i (x_i - \E\xi)^2 - p_i\) при условии, что данное значение существует \textit{(конечно)}.
\end{definition}

\begin{remark}
    Вычислять дисперсию удобнее по формуле \(\D\xi = \E\xi^2 - (\E\xi)^2 = \sum_i x_i^2 p_i - (\E\xi)^2\)
\end{remark}

\begin{remark}
    Смысл: квадрат среднего разброса рассеяния случайной величины около её математического ожидания.
\end{remark}

\subsubsection{Среднеквадратическое отклонение}

\begin{definition}
    \textbf{Среднеквадратическим отклонением} \(\sigma_\xi\) случайной величины \(\xi\) называется число \(\sigma = \sqrt{\D\xi}\)
\end{definition}

\begin{remark}
    Смысл: характеризует средний разброс случайной величины около её математического ожидания.
\end{remark}
%</17>

\begin{example}
    Кость.

    \begin{tabular}{C|C|C|C|C|C|C}
        \xi & 1           & 2           & 3           & 4           & 5           & 6           \\ \hline
        P   & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6}
    \end{tabular}

    \[\E\xi = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5\]
    \[\D\xi = 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} - 3.5^2 \approx 2.32\]
    \[\sigma \approx \sqrt{2.32} \approx 1.71\]
\end{example}

\subsection{Свойства математического ожидания и дисперсии}

\begin{definition}
    Случайная величина \(\xi\) имеет вырожденное распределение, если \(\xi(w) = C \ \ \forall w \in \Omega\).
\end{definition}

%<*18>
\begin{prop}\itemfix
    \begin{enumerate}
        \item \(\E C = C, \D C = 0\)
              \begin{proof}
                  \[\E C = C \cdot 1 = C\]
                  \[\D C = \E(\underbrace{C - \E C}_0) = 0\]
              \end{proof}

        \item \(\E(\xi + C) = \E\xi + C, \D(\xi + C) = \D\xi\)
              \begin{proof}
                  \[\E(\xi + C) = \sum_i (x_i + C)p_i = \sum_i x_i p_i + C \underbrace{\sum_i p_i}_1 = \E\xi + C\]
                  \[\D(\xi + C) =  \E(\xi + C - \E(\xi + C))^2 = \E(\xi + C - \E\xi - C)^2 = \E(\xi - \E\xi)^2 = \D\xi\]
              \end{proof}

        \item Растяжение: \(\E(C\xi) = C \E\xi, \D(C\xi) = C^2 \D\xi\)
              \begin{proof}
                  \[\E(C\xi) = \sum_i C x_i p_i = C \sum_i x_i p_i = C \E\xi\]
                  \[\D(C\xi) = \E(C\xi - \E C\xi)^2 = C^2 \E(\xi - \E\xi)^2 = C^2 \D\xi\]
              \end{proof}

        \item \(\E(\xi + \eta) = \E\xi + \E\eta\)
              \begin{proof}
                  Пусть \(x_i, y_j\) --- соответствующие значения случайных величин \(\xi\) и \(\eta\).

                  \begin{align*}
                      \E(\xi + \eta) & = \sum_{i, j} (x_i + y_j)P(\xi = x_i, \eta = y_j)                                         \\
                                     & = \sum_i x_i \sum_j P(\xi = x_i, \eta = y_j) + \sum_j y_j \sum_i P(\xi = x_j, \eta = y_i) \\
                                     & = \sum_i x_i P(\xi = x_i) + \sum_j y_j P(\eta = y_j)                                      \\
                                     & = \E \xi + \E \eta
                  \end{align*}

              \end{proof}

              \begin{definition}
                  Дискретные случайные величины \(\xi\) и \(\eta\) \textbf{независимы}, если \(P(\xi = x_i, \eta = y_j) = P(\xi = x_i)P(\eta = y_j) \ \ \forall i,j\), т.е. случайные величины принимают свои значения независимо друг от друга.
              \end{definition}

        \item Если \(\xi\) и \(\eta\) независимы, то \(\E(\xi\cdot\eta) = \E\xi\cdot\E\eta\)
              \begin{proof}
                  \begin{align*}
                      \E(\xi\cdot\eta) & = \sum_{i, j} x_i y_j P(\xi = x_i, \eta = y_j)     \\
                                       & = \sum_i x_i \sum_j y_j P(\xi = x_i, \eta = y_j)   \\
                                       & = \sum_i x_i \sum_j y_j P(\xi = x_i) P(\eta = y_j) \\
                                       & = \sum_i x_i P(\xi = x_i) \sum_j y_j P(\eta = y_j) \\
                                       & = \sum_i x_i P(\xi = x_i) \E\eta                   \\
                                       & = \E\xi \E\eta                                     \\
                  \end{align*}
              \end{proof}

              В обратную сторону это утверждение не верно.

        \item \(\D\xi = \E\xi^2 - (\E\xi)^2\)
              \begin{proof}
                  \begin{align*}
                      \D\xi & = \E(\xi - \E\xi^2)                     \\
                            & = \E(\xi^2 - 2\xi\E\xi + (\E\xi)^2)     \\
                            & = \E\xi^2 - 2 \E\xi \E\xi + \E(\E\xi^2) \\
                            & = \E\xi^2 - 2(\E\xi)^2 + (\E\xi)^2      \\
                            & = \E\xi^2 - (\E\xi)^2
                  \end{align*}
              \end{proof}

        \item \(\D(\xi + \eta) = \D\xi + \D\eta + 2 \cdot \cov(\xi, \eta)\), где \(\cov(\xi, \eta) = \E(\xi \cdot \eta) - \E\xi \cdot \E \eta\) --- ковариация.

              \begin{proof}
                  \begin{align*}
                      \D(\xi + \eta) & = \E(\xi + \eta)^2 - (\E(\xi + \eta))^2                                         \\
                                     & = \E(\xi^2 + 2\xi\eta + \eta^2) - (\E\xi + \E\eta)^2                            \\
                                     & = \E \xi^2 + 2 \E \xi\eta + \E \eta^2 - (\E \xi)^2 - (\E \eta)^2 - 2\E\xi\E\eta \\
                                     & = \D\xi + \D\eta + 2 (\E \xi\eta - \E\xi\E\eta)                                 \\
                  \end{align*}
              \end{proof}

        \item Если случайные величины \(\xi\) и \(\eta\) независимы, то \(\D(\xi + \eta) = \D \xi + \D \eta\)

              \begin{proof}
                  \(\cov(\xi, \eta) = 0\)
              \end{proof}

        \item Среднеквадратическое отклонение --- минимум отклонения случайной величины от точек вещественной прямой: \(\D = \min_a (\xi - a)^2\)

              \begin{proof}
                  \begin{align*}
                      \E(\xi - a)^2 & = \E((\xi - \E\xi) + (\E\xi - a))^2                                       \\
                                    & = \E(\xi - \E\xi)^2 + 2\E(\xi - \E\xi) \cdot (\E \xi - a) + (\E\xi - a)^2 \\
                                    & = \D\xi + (\E\xi - a)^2 \leq \D\xi
                  \end{align*}
              \end{proof}
    \end{enumerate}
\end{prop}
%</18>

\subsection{Другие числовые характеристики}

\begin{enumerate}
    \item \(M_k = \E y^k\) --- момент \(k\)-го порядка. В частности, при \(k = 1\) это матожидание.
    \item \(\E|y|^k\) --- абсолютный момент \(k\)-го порядка
    \item \(\mu_k = \E(\xi - \E\xi)^k\) --- центральный момент \(k\)-го порядка. В частности, при \(k = 1\) это дисперсия.
    \item \(\E(\xi - \E\xi)^k\) --- абсолютный центральный момент \(k\)-го порядка.
\end{enumerate}

\begin{remark}
    Центральные моменты можно выразить через моменты.
\end{remark}

\begin{remark}
    Обычно не рассматривают моменты выше, чем \(4\) порядка.
\end{remark}

\subsubsection{Мода}

\begin{definition}
    \textbf{Модой} \(M_o\) называется такое значение случайной величины, где вероятность события является наибольшей: \(P(\xi - M_o) = \max_i p_i\)
\end{definition}

\subsubsection{Медиана}

\begin{definition}
    \textbf{Медианой} \(M_e\) называется значение случайной величины такое, что вероятность того, что \(P(\xi < M_e) = P(\xi > M_e)\). Обычно используется для обычной случайной величины, т.к. для дискретной величины медиана может не существовать.
\end{definition}
